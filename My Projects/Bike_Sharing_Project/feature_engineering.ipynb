{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "# Load cleaned data\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_bike_data.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: cleaned_bike_data.csv not found. Run EDA first.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "# --- 1. Feature Engineering ---\n",
    "\n",
    "# A. Categorical Encoding\n",
    "# Check unique values\n",
    "print(\"\\nUnique values in 'season':\", df['season'].unique())\n",
    "print(\"Unique values in 'weathersit':\", df['weathersit'].unique())\n",
    "\n",
    "# Ordinal/Label Mappings (if needed) or One-Hot\n",
    "# If 'season' is string, we might want to map it to numbers or OHE. \n",
    "# Problem statement mentions: \"Handle categorical variables through techniques like one-hot encoding\"\n",
    "\n",
    "# Let's use One-Hot Encoding for 'season' and 'weathersit'\n",
    "# We will use pd.get_dummies for simplicity and readability\n",
    "df = pd.get_dummies(df, columns=['season', 'weathersit'], prefix=['season', 'weather'], drop_first=True)\n",
    "print(\"Applied One-Hot Encoding. New columns:\", df.columns[df.columns.str.startswith('season_') | df.columns.str.startswith('weather_')])\n",
    "\n",
    "# B. Cyclic Encoding for Time Variables (hr, mnth, weekday)\n",
    "# This enables models to understand that hour 23 is close to hour 0\n",
    "def encode_cyclic(df, col, max_val):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    return df\n",
    "\n",
    "df = encode_cyclic(df, 'hr', 24)\n",
    "df = encode_cyclic(df, 'mnth', 12)\n",
    "df = encode_cyclic(df, 'weekday', 7)\n",
    "\n",
    "print(\"Applied Cyclic Encoding for hr, mnth, weekday.\")\n",
    "\n",
    "# C. Handling 'dteday'\n",
    "# We have already extracted yr, mnth, weekday, season. \n",
    "# 'dteday' itself is not needed for the model directly, but 'day' might be useful?\n",
    "# Usually day of month (1-31) implies pay-day effects etc.\n",
    "df['dteday'] = pd.to_datetime(df['dteday'])\n",
    "df['day'] = df['dteday'].dt.day\n",
    "# Cyclic encode day?\n",
    "df = encode_cyclic(df, 'day', 31)\n",
    "\n",
    "# Drop original 'dteday' and 'instant' as they are not predictive features\n",
    "drop_cols = ['dteday', 'instant']\n",
    "df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# D. Scaling Numerical Features\n",
    "# We scale features like temp, atemp, hum, windspeed\n",
    "# We do NOT scale target variables (cnt, casual, registered)\n",
    "scale_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "scaler = MinMaxScaler() # Normalizing to 0-1 as indicated in problem (\"Normalized temperature\", etc)\n",
    "# Note: The original dataset says they are normalized, but let's ensure it or re-scale if we imputed.\n",
    "# Since we imputed, values might be slightly off structure, so good to re-ensure.\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "print(\"Scaled feature columns.\")\n",
    "\n",
    "# --- 2. Correlation Analysis on New Features ---\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix (Processed Features)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/correlation_matrix_processed.png')\n",
    "print(\"Saved features correlation matrix.\")\n",
    "\n",
    "# --- 3. Save Processed Data ---\n",
    "df.to_csv('processed_bike_data.csv', index=False)\n",
    "print(\"\\nSaved processed dataset to 'processed_bike_data.csv'\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(\"Final columns:\", df.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
