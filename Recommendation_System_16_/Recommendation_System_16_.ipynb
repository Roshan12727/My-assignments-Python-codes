{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26597366"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b857dec3",
        "outputId": "99db5152-ec2a-4816-d136-c95eb61b8f0a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "anime_df = pd.read_csv('/content/anime.csv')\n",
        "print(\"Dataset loaded successfully. Displaying the first 5 rows:\")\n",
        "print(anime_df.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Displaying the first 5 rows:\n",
            "   anime_id                              name  \\\n",
            "0     32281                    Kimi no Na wa.   \n",
            "1      5114  Fullmetal Alchemist: Brotherhood   \n",
            "2     28977                          GintamaÂ°   \n",
            "3      9253                       Steins;Gate   \n",
            "4      9969                     Gintama&#039;   \n",
            "\n",
            "                                               genre   type episodes  rating  \\\n",
            "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
            "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
            "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
            "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
            "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
            "\n",
            "   members  \n",
            "0   200630  \n",
            "1   793665  \n",
            "2   114262  \n",
            "3   673572  \n",
            "4   151266  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a19f7e90"
      },
      "source": [
        "## Initial Data Inspection and Missing Value Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00e718c5"
      },
      "source": [
        "To understand the structure, data types, and non-null values of the `anime_df` DataFrame, I will use the `.info()` method. This will help identify columns that might require type conversion or have a significant number of missing values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4c6620c",
        "outputId": "b050837b-6bf4-4b30-88a9-c7b60ece20c3"
      },
      "source": [
        "print(\"DataFrame Info:\")\n",
        "anime_df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12294 entries, 0 to 12293\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   anime_id  12294 non-null  int64  \n",
            " 1   name      12294 non-null  object \n",
            " 2   genre     12232 non-null  object \n",
            " 3   type      12269 non-null  object \n",
            " 4   episodes  12294 non-null  object \n",
            " 5   rating    12064 non-null  float64\n",
            " 6   members   12294 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(4)\n",
            "memory usage: 672.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77c5ef24"
      },
      "source": [
        "To get a statistical summary of the numerical columns in `anime_df`, I will use the `.describe()` method. This will provide insights into the distribution and central tendency of these columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ff3ee53",
        "outputId": "2bc90961-fabb-4f0a-dd59-f5938d095e9f"
      },
      "source": [
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(anime_df.describe())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Descriptive Statistics:\n",
            "           anime_id        rating       members\n",
            "count  12294.000000  12064.000000  1.229400e+04\n",
            "mean   14058.221653      6.473902  1.807134e+04\n",
            "std    11455.294701      1.026746  5.482068e+04\n",
            "min        1.000000      1.670000  5.000000e+00\n",
            "25%     3484.250000      5.880000  2.250000e+02\n",
            "50%    10260.500000      6.570000  1.550000e+03\n",
            "75%    24794.500000      7.180000  9.437000e+03\n",
            "max    34527.000000     10.000000  1.013917e+06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ac0e426"
      },
      "source": [
        "To identify which columns have missing values and the extent of those missing values, I will use the `.isnull().sum()` method on the `anime_df` DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33195529",
        "outputId": "c5ae30af-d01b-44da-ed75-09e3e64b6074"
      },
      "source": [
        "print(\"\\nMissing values per column:\")\n",
        "print(anime_df.isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n",
            "anime_id      0\n",
            "name          0\n",
            "genre        62\n",
            "type         25\n",
            "episodes      0\n",
            "rating      230\n",
            "members       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fe5a9b5"
      },
      "source": [
        "Based on the missing value counts, I will fill missing 'genre' and 'type' values with 'Unknown' and missing 'rating' values with the mean of the 'rating' column to handle them appropriately.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11449c23",
        "outputId": "609c2057-92b5-4dde-eac9-4b2755109244"
      },
      "source": [
        "anime_df['genre'].fillna('Unknown', inplace=True)\n",
        "anime_df['type'].fillna('Unknown', inplace=True)\n",
        "anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n",
        "\n",
        "print(\"Missing values after handling:\")\n",
        "print(anime_df.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after handling:\n",
            "anime_id    0\n",
            "name        0\n",
            "genre       0\n",
            "type        0\n",
            "episodes    0\n",
            "rating      0\n",
            "members     0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2093343244.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anime_df['genre'].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-2093343244.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anime_df['type'].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-2093343244.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "770322ec"
      },
      "source": [
        "The previous code block produced a `FutureWarning` due to the use of `inplace=True` with chained assignment. To address this, I will modify the `fillna` operations to directly assign the result back to the DataFrame columns, as suggested by the warning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2afbf9",
        "outputId": "52d60e3c-8a3e-41f3-e5e1-03cc1fbc393f"
      },
      "source": [
        "anime_df['genre'] = anime_df['genre'].fillna('Unknown')\n",
        "anime_df['type'] = anime_df['type'].fillna('Unknown')\n",
        "anime_df['rating'] = anime_df['rating'].fillna(anime_df['rating'].mean())\n",
        "\n",
        "print(\"Missing values after handling:\")\n",
        "print(anime_df.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after handling:\n",
            "anime_id    0\n",
            "name        0\n",
            "genre       0\n",
            "type        0\n",
            "episodes    0\n",
            "rating      0\n",
            "members     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30f3998a"
      },
      "source": [
        "## Feature Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8023fb"
      },
      "source": [
        "To understand the various formats and non-numeric entries present in the 'episodes' column, I need to inspect its unique values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27688e2f",
        "outputId": "79cf76c1-25f3-48e2-8824-c7e45cbb7570"
      },
      "source": [
        "print(\"Unique values in 'episodes' column:\")\n",
        "print(anime_df['episodes'].unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'episodes' column:\n",
            "['1' '64' '51' '24' '10' '148' '110' '13' '201' '25' '22' '75' '4' '26'\n",
            " '12' '27' '43' '74' '37' '2' '11' '99' 'Unknown' '39' '101' '47' '50'\n",
            " '62' '33' '112' '23' '3' '94' '6' '8' '14' '7' '40' '15' '203' '77' '291'\n",
            " '120' '102' '96' '38' '79' '175' '103' '70' '153' '45' '5' '21' '63' '52'\n",
            " '28' '145' '36' '69' '60' '178' '114' '35' '61' '34' '109' '20' '9' '49'\n",
            " '366' '97' '48' '78' '358' '155' '104' '113' '54' '167' '161' '42' '142'\n",
            " '31' '373' '220' '46' '195' '17' '1787' '73' '147' '127' '16' '19' '98'\n",
            " '150' '76' '53' '124' '29' '115' '224' '44' '58' '93' '154' '92' '67'\n",
            " '172' '86' '30' '276' '59' '72' '330' '41' '105' '128' '137' '56' '55'\n",
            " '65' '243' '193' '18' '191' '180' '91' '192' '66' '182' '32' '164' '100'\n",
            " '296' '694' '95' '68' '117' '151' '130' '87' '170' '119' '84' '108' '156'\n",
            " '140' '331' '305' '300' '510' '200' '88' '1471' '526' '143' '726' '136'\n",
            " '1818' '237' '1428' '365' '163' '283' '71' '260' '199' '225' '312' '240'\n",
            " '1306' '1565' '773' '1274' '90' '475' '263' '83' '85' '1006' '80' '162'\n",
            " '132' '141' '125']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b9eef54"
      },
      "source": [
        "Based on the inspection of unique values, I will replace 'Unknown' in the 'episodes' column with 0 and then convert the column to an integer type to make it numerical for further processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b415353",
        "outputId": "1850706a-6c74-4177-fb9c-29b27053815b"
      },
      "source": [
        "anime_df['episodes'] = anime_df['episodes'].replace('Unknown', 0).astype(int)\n",
        "print(\"'episodes' column after cleaning and type conversion:\")\n",
        "print(anime_df['episodes'].head())\n",
        "print(\"Data type of 'episodes' column:\", anime_df['episodes'].dtype)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'episodes' column after cleaning and type conversion:\n",
            "0     1\n",
            "1    64\n",
            "2    51\n",
            "3    24\n",
            "4    51\n",
            "Name: episodes, dtype: int64\n",
            "Data type of 'episodes' column: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48972c6b"
      },
      "source": [
        "To prepare the 'genre' column for one-hot encoding, I will first split the comma-separated genre strings into individual genres and then collect all unique genres present in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31eb040b",
        "outputId": "476a7a6a-eccb-46c9-fa17-d9b92c94ddc1"
      },
      "source": [
        "all_genres = set()\n",
        "for genres_str in anime_df['genre']:\n",
        "    for genre in genres_str.split(', '):\n",
        "        all_genres.add(genre.strip())\n",
        "\n",
        "print(\"Total unique genres found:\", len(all_genres))\n",
        "print(\"First 10 unique genres:\", list(all_genres)[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique genres found: 44\n",
            "First 10 unique genres: ['Slice of Life', 'Super Power', 'Mystery', 'Josei', 'Vampire', 'Unknown', 'Historical', 'Parody', 'School', 'Sports']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02d5ed9"
      },
      "source": [
        "Now that all unique genres have been identified, I will apply one-hot encoding to the 'genre' column by creating new binary columns for each genre. Each new column will indicate the presence (1) or absence (0) of that genre for each anime.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5cbf1d8",
        "outputId": "e1a932c8-5dde-45b4-bb1c-f1c4dd3b5a65"
      },
      "source": [
        "for genre in all_genres:\n",
        "    anime_df[genre] = anime_df['genre'].apply(lambda x: 1 if genre in x else 0)\n",
        "\n",
        "print(\"DataFrame with one-hot encoded genres (first 5 rows and genre columns):\")\n",
        "print(anime_df[list(all_genres)[:5] + ['genre']].head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with one-hot encoded genres (first 5 rows and genre columns):\n",
            "   Slice of Life  Super Power  Mystery  Josei  Vampire  \\\n",
            "0              0            0        0      0        0   \n",
            "1              0            0        0      0        0   \n",
            "2              0            0        0      0        0   \n",
            "3              0            0        0      0        0   \n",
            "4              0            0        0      0        0   \n",
            "\n",
            "                                               genre  \n",
            "0               Drama, Romance, School, Supernatural  \n",
            "1  Action, Adventure, Drama, Fantasy, Magic, Mili...  \n",
            "2  Action, Comedy, Historical, Parody, Samurai, S...  \n",
            "3                                   Sci-Fi, Thriller  \n",
            "4  Action, Comedy, Historical, Parody, Samurai, S...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa30c405"
      },
      "source": [
        "To one-hot encode the 'type' column, I will use `pd.get_dummies()` and then concatenate the resulting DataFrame with the original `anime_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c386b7ac",
        "outputId": "1e94e794-be04-4675-b8f8-878e476bda58"
      },
      "source": [
        "type_dummies = pd.get_dummies(anime_df['type'], prefix='type')\n",
        "anime_df = pd.concat([anime_df, type_dummies], axis=1)\n",
        "\n",
        "print(\"DataFrame with one-hot encoded 'type' column (first 5 rows and type columns):\")\n",
        "print(anime_df[[col for col in anime_df.columns if 'type_' in col or col == 'type']].head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with one-hot encoded 'type' column (first 5 rows and type columns):\n",
            "    type  type_Movie  type_Music  type_ONA  type_OVA  type_Special  type_TV  \\\n",
            "0  Movie        True       False     False     False         False    False   \n",
            "1     TV       False       False     False     False         False     True   \n",
            "2     TV       False       False     False     False         False     True   \n",
            "3     TV       False       False     False     False         False     True   \n",
            "4     TV       False       False     False     False         False     True   \n",
            "\n",
            "   type_Unknown  \n",
            "0         False  \n",
            "1         False  \n",
            "2         False  \n",
            "3         False  \n",
            "4         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "338dc303"
      },
      "source": [
        "To normalize the numerical features 'rating' and 'members', I first need to import the `StandardScaler` from `sklearn.preprocessing`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74a47119",
        "outputId": "c1282a30-e7e9-4a29-e4e2-b45c332624b7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"StandardScaler imported successfully.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StandardScaler imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0611e0cb"
      },
      "source": [
        "Now that `StandardScaler` is imported, I will initialize a `StandardScaler` object and then use it to fit and transform the 'rating' and 'members' columns, storing the results in new 'rating_scaled' and 'members_scaled' columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9988432",
        "outputId": "75d9eeb2-bcee-4c6e-e56a-c5287cb7361c"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "anime_df['rating_scaled'] = scaler.fit_transform(anime_df[['rating']])\n",
        "anime_df['members_scaled'] = scaler.fit_transform(anime_df[['members']])\n",
        "\n",
        "print(\"Numerical features 'rating' and 'members' scaled successfully.\")\n",
        "print(anime_df[['rating', 'rating_scaled', 'members', 'members_scaled']].head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical features 'rating' and 'members' scaled successfully.\n",
            "   rating  rating_scaled  members  members_scaled\n",
            "0    9.37       2.847535   200630        3.330241\n",
            "1    9.26       2.739380   793665       14.148406\n",
            "2    9.25       2.729547   114262        1.754713\n",
            "3    9.17       2.650889   673572       11.957666\n",
            "4    9.16       2.641057   151266        2.429742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f053674"
      },
      "source": [
        "## Combine Features and Compute Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47a97b29"
      },
      "source": [
        "To combine all preprocessed features, I first need to identify all columns that represent genres (one-hot encoded), types (one-hot encoded), and the scaled numerical features ('rating_scaled' and 'members_scaled'). I will create a list of these column names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21cfe255",
        "outputId": "6d036def-fd11-433e-f0d8-51bcda9e1794"
      },
      "source": [
        "genre_cols = [col for col in anime_df.columns if col in all_genres]\n",
        "type_cols = [col for col in anime_df.columns if 'type_' in col]\n",
        "\n",
        "feature_cols = genre_cols + type_cols + ['rating_scaled', 'members_scaled']\n",
        "\n",
        "print(\"Identified feature columns:\")\n",
        "print(feature_cols[:10]) # Print first 10 for brevity\n",
        "print(f\"Total feature columns: {len(feature_cols)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified feature columns:\n",
            "['Slice of Life', 'Super Power', 'Mystery', 'Josei', 'Vampire', 'Unknown', 'Historical', 'Parody', 'School', 'Sports']\n",
            "Total feature columns: 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b487275"
      },
      "source": [
        "Now that the feature columns are identified, I will create the `feature_matrix` DataFrame, import `cosine_similarity`, compute the cosine similarity matrix, and print its shape as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d478e7d",
        "outputId": "a4537b94-d5a6-466f-96fc-e075204ab6f9"
      },
      "source": [
        "feature_matrix = anime_df[feature_cols]\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_sim = cosine_similarity(feature_matrix)\n",
        "\n",
        "print(\"Shape of the cosine similarity matrix:\", cosine_sim.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the cosine similarity matrix: (12294, 12294)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9613c810"
      },
      "source": [
        "## Implement Recommendation Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dcb458c"
      },
      "source": [
        "I need to define the `get_recommendations` function, which will take an anime title, find its index in the DataFrame, retrieve its similarity scores from the precomputed `cosine_sim` matrix, sort these scores, and then return the names of the top N most similar anime, excluding the input anime itself.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e0f1ab6",
        "outputId": "77b33868-6a32-4afb-e021-7fc7be8d89f7"
      },
      "source": [
        "def get_recommendations(anime_title, n_recommendations=10):\n",
        "    # Find the index of the target anime\n",
        "    if anime_title not in anime_df['name'].values:\n",
        "        print(f\"Anime '{anime_title}' not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    idx = anime_df[anime_df['name'] == anime_title].index[0]\n",
        "\n",
        "    # Get the similarity scores for this anime\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the anime based on the similarity scores in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the top N most similar anime, excluding itself\n",
        "    # The first element is always the anime itself with a similarity of 1, so skip it.\n",
        "    sim_scores = sim_scores[1:n_recommendations+1]\n",
        "\n",
        "    # Get the anime indices\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top N recommended anime names\n",
        "    return anime_df['name'].iloc[anime_indices].tolist()\n",
        "\n",
        "print(\"Recommendation function 'get_recommendations' defined.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendation function 'get_recommendations' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9dc595d"
      },
      "source": [
        "\n",
        "The subtask of defining the `get_recommendations` function has been completed in the previous turn. Now, I need to test the function to ensure it works as expected by calling it with an example anime title and displaying the recommendations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f259412b",
        "outputId": "3130bfb5-9f82-411b-e7b9-41e1230658a1"
      },
      "source": [
        "print(\"Recommendations for 'Kimi no Na wa.':\")\n",
        "recommendations = get_recommendations('Kimi no Na wa.')\n",
        "print(recommendations)\n",
        "\n",
        "print(\"\\nRecommendations for 'Fullmetal Alchemist: Brotherhood':\")\n",
        "recommendations = get_recommendations('Fullmetal Alchemist: Brotherhood')\n",
        "print(recommendations)\n",
        "\n",
        "print(\"\\nRecommendations for a non-existent anime:\")\n",
        "recommendations = get_recommendations('NonExistentAnimeTitle')\n",
        "print(recommendations)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'Kimi no Na wa.':\n",
            "['Hotarubi no Mori e', 'Suzumiya Haruhi no Shoushitsu', 'Hotaru no Haka', 'Clannad: After Story - Mou Hitotsu no Sekai, Kyou-hen', 'Kotonoha no Niwa', 'Yahari Ore no Seishun Love Comedy wa Machigatteiru. Zoku', 'Howl no Ugoku Shiro', 'Toki wo Kakeru Shoujo', 'Kanon (2006)', 'Clannad: Mou Hitotsu no Sekai, Tomoyo-hen']\n",
            "\n",
            "Recommendations for 'Fullmetal Alchemist: Brotherhood':\n",
            "['Fullmetal Alchemist', 'Shingeki no Kyojin', 'Fairy Tail', 'Akame ga Kill!', 'Noragami', 'Soul Eater', 'Sword Art Online', 'One Piece', 'Ao no Exorcist', 'Angel Beats!']\n",
            "\n",
            "Recommendations for a non-existent anime:\n",
            "Anime 'NonExistentAnimeTitle' not found in the dataset.\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70bbdb33"
      },
      "source": [
        "## Analyze Recommendations and Thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b860d37"
      },
      "source": [
        "To allow filtering recommendations based on similarity, I need to modify the `get_recommendations` function to accept a `similarity_threshold` parameter and filter the results accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8191201",
        "outputId": "a4800528-1b40-466b-afbe-1404c2aa4061"
      },
      "source": [
        "def get_recommendations(anime_title, n_recommendations=10, similarity_threshold=0):\n",
        "    # Find the index of the target anime\n",
        "    if anime_title not in anime_df['name'].values:\n",
        "        print(f\"Anime '{anime_title}' not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    idx = anime_df[anime_df['name'] == anime_title].index[0]\n",
        "\n",
        "    # Get the similarity scores for this anime\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the anime based on the similarity scores in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Filter out recommendations below the threshold and the anime itself\n",
        "    filtered_scores = [s for s in sim_scores if s[1] >= similarity_threshold and s[0] != idx]\n",
        "\n",
        "    # Get the scores of the top N most similar anime\n",
        "    sim_scores = filtered_scores[:n_recommendations]\n",
        "\n",
        "    # Get the anime indices\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top N recommended anime names\n",
        "    return anime_df['name'].iloc[anime_indices].tolist(), [i[1] for i in sim_scores]\n",
        "\n",
        "print(\"Recommendation function 'get_recommendations' modified to include similarity_threshold.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendation function 'get_recommendations' modified to include similarity_threshold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a40d0d27"
      },
      "source": [
        "Now that the `get_recommendations` function is updated, I will test it with different `similarity_threshold` values as per the instructions, printing the threshold, recommendations, and their count for analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1777bad",
        "outputId": "73cda6f8-7035-43e6-cbca-fd24bbfe9bf6"
      },
      "source": [
        "anime_to_recommend = 'Kimi no Na wa.'\n",
        "similarity_thresholds = [0.5, 0.7, 0.9]\n",
        "\n",
        "for threshold in similarity_thresholds:\n",
        "    print(f\"\\n--- Recommendations for '{anime_to_recommend}' with similarity_threshold = {threshold} ---\")\n",
        "    recommendations, scores = get_recommendations(anime_to_recommend, n_recommendations=10, similarity_threshold=threshold)\n",
        "    if recommendations:\n",
        "        for i, (rec, score) in enumerate(zip(recommendations, scores)):\n",
        "            print(f\"{i+1}. {rec} (Similarity: {score:.2f})\")\n",
        "    else:\n",
        "        print(\"No recommendations found above this threshold.\")\n",
        "    print(f\"Total recommendations: {len(recommendations)}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Recommendations for 'Kimi no Na wa.' with similarity_threshold = 0.5 ---\n",
            "1. Hotarubi no Mori e (Similarity: 0.95)\n",
            "2. Suzumiya Haruhi no Shoushitsu (Similarity: 0.91)\n",
            "3. Hotaru no Haka (Similarity: 0.90)\n",
            "4. Clannad: After Story - Mou Hitotsu no Sekai, Kyou-hen (Similarity: 0.89)\n",
            "5. Kotonoha no Niwa (Similarity: 0.89)\n",
            "6. Yahari Ore no Seishun Love Comedy wa Machigatteiru. Zoku (Similarity: 0.89)\n",
            "7. Howl no Ugoku Shiro (Similarity: 0.88)\n",
            "8. Toki wo Kakeru Shoujo (Similarity: 0.88)\n",
            "9. Kanon (2006) (Similarity: 0.88)\n",
            "10. Clannad: Mou Hitotsu no Sekai, Tomoyo-hen (Similarity: 0.87)\n",
            "Total recommendations: 10\n",
            "\n",
            "--- Recommendations for 'Kimi no Na wa.' with similarity_threshold = 0.7 ---\n",
            "1. Hotarubi no Mori e (Similarity: 0.95)\n",
            "2. Suzumiya Haruhi no Shoushitsu (Similarity: 0.91)\n",
            "3. Hotaru no Haka (Similarity: 0.90)\n",
            "4. Clannad: After Story - Mou Hitotsu no Sekai, Kyou-hen (Similarity: 0.89)\n",
            "5. Kotonoha no Niwa (Similarity: 0.89)\n",
            "6. Yahari Ore no Seishun Love Comedy wa Machigatteiru. Zoku (Similarity: 0.89)\n",
            "7. Howl no Ugoku Shiro (Similarity: 0.88)\n",
            "8. Toki wo Kakeru Shoujo (Similarity: 0.88)\n",
            "9. Kanon (2006) (Similarity: 0.88)\n",
            "10. Clannad: Mou Hitotsu no Sekai, Tomoyo-hen (Similarity: 0.87)\n",
            "Total recommendations: 10\n",
            "\n",
            "--- Recommendations for 'Kimi no Na wa.' with similarity_threshold = 0.9 ---\n",
            "1. Hotarubi no Mori e (Similarity: 0.95)\n",
            "2. Suzumiya Haruhi no Shoushitsu (Similarity: 0.91)\n",
            "3. Hotaru no Haka (Similarity: 0.90)\n",
            "Total recommendations: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "985bfcfd"
      },
      "source": [
        "### Interpretation of Recommendations and Potential Improvements\n",
        "\n",
        "**Interpretation of Recommendations:**\n",
        "\n",
        "By experimenting with different `similarity_threshold` values, we can observe its direct impact on the number and perceived quality of recommendations:\n",
        "\n",
        "*   **Lower Thresholds (e.g., 0.5):** A lower threshold like 0.5 provides a broader range of recommendations. As seen with 'Kimi no Na wa.', this might include anime that share general characteristics (e.g., genre, type, high rating) but might not be as directly similar in specific nuances. The recommendations are plentiful, but their relevance might vary.\n",
        "*   **Higher Thresholds (e.g., 0.7, 0.9):** As the threshold increases, the number of recommendations decreases significantly. This indicates that the system is becoming more selective, only suggesting anime that are very closely aligned with the input anime's features. For 'Kimi no Na wa.' at a threshold of 0.9, only three highly similar anime were returned, implying a very strong match based on the defined features. While the quantity is lower, the quality (i.e., direct relevance) is likely higher.\n",
        "\n",
        "The choice of threshold depends on the desired user experience. A lower threshold might be good for exploration, while a higher threshold is better for finding very specific, similar content.\n",
        "\n",
        "**Potential Improvements:**\n",
        "\n",
        "1.  **Enriching Features:**\n",
        "    *   **Synopsis/Description Text Analysis:** Incorporate natural language processing (NLP) on anime synopses or descriptions to extract thematic similarities, keywords, or even sentiment. This could capture more nuanced content-based similarities that aren't apparent from genre or type.\n",
        "    *   **Character/Staff Data:** Including data about voice actors, directors, studios, and main characters could add another layer of similarity, as users often follow works by specific creators or voice artists.\n",
        "    *   **User Ratings/Reviews:** While the 'rating' column is used, incorporating average user ratings or even performing matrix factorization on a full user-item rating matrix (if available) would allow for true collaborative filtering elements, capturing user preferences beyond content features.\n",
        "\n",
        "2.  **Hybrid Approaches:** Combine content-based filtering (what we've implemented) with collaborative filtering (if user-item interaction data were available). This can leverage the strengths of both, providing recommendations that are both similar in content and popular among users with similar tastes.\n",
        "\n",
        "3.  **Advanced Feature Engineering:**\n",
        "    *   **Genre Weighting:** Some genres might be more important to a user than others. Instead of simple one-hot encoding, a weighted approach could be considered.\n",
        "    *   **Temporal Dynamics:** If release dates were considered, recommendations could prioritize newer or older anime based on user preferences.\n",
        "\n",
        "4.  **Handling Cold Start:** For new anime or anime with limited data, the current system might struggle. Hybrid models or leveraging external metadata could help address this.\n",
        "\n",
        "5.  **User Interface and Feedback:** Implement a way for users to provide feedback on recommendations (e.g.,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e914bdcf"
      },
      "source": [
        "## Answer Interview Questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da82b94"
      },
      "source": [
        "\n",
        "### Q&A\n",
        "\n",
        "**1. What is collaborative filtering, and how does it work?**\n",
        "Collaborative filtering is a recommendation technique that predicts user interest in items by leveraging the preferences of many users. Its core principle is that if users share similar tastes for some items, they will likely have similar preferences for others. It works by:\n",
        "1.  **Collecting User Behavior Data**: Gathering explicit (e.g., ratings) or implicit (e.g., viewing history) feedback on user-item interactions.\n",
        "2.  **Finding Patterns**: Analyzing this data to identify similarities among users or items.\n",
        "3.  **Making Recommendations**: Suggesting items to a target user based on these identified patterns, assuming that \"people who agreed in the past tend to agree in the future\" or \"items liked by similar people are likely to be liked by you.\"\n",
        "\n",
        "**2. Can you explain the difference between user-based and item-based collaborative filtering?**\n",
        "\n",
        "| Feature | User-Based Collaborative Filtering | Item-Based Collaborative Filtering |\n",
        "| :----------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Core Idea** | Recommends items to a user based on the preferences of similar users (\"Show me what people like me liked.\"). | Recommends items to a user based on the similarity between items (\"Since you liked this item, you might also like these other similar items.\"). |\n",
        "| **Similarity Calculation** | Calculates similarity between **users** based on their shared item preferences. | Calculates similarity between **items** based on how users have interacted with them. |\n",
        "| **Recommendation Process** | 1. Find users similar to the target user. <br> 2. Recommend items liked by those similar users but not yet seen by the target user. | 1. Identify items the target user has liked. <br> 2. Find items similar to those liked items. <br> 3. Recommend these similar items not yet seen by the target user. |\n",
        "| **Computational Cost** | Can be computationally expensive for a large number of users, as user preferences are dynamic. | Often more scalable for large user bases, as item similarity is generally more stable and can be precomputed. |\n",
        "| **Sparsity Issue** | More prone to data sparsity if users have rated very few items. | Generally less affected by user sparsity, as item-item relationships are derived from collective user behavior. |\n",
        "| **Cold Start Problem** | **User Cold Start**: Difficult to recommend for new users with no interaction history. | **Item Cold Start**: Difficult to recommend new items with no interaction history. |\n"
      ]
    }
  ]
}